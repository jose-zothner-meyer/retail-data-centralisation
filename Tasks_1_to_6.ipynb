{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinational Retail Data Centralisation Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim\n",
    "\n",
    "<b>To go through what its like to source, clean and centralise retail sales data to a database which can then be queried and for analysis.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this project I will learn to:\n",
    "\n",
    "1. Extract data from various sources like AWS RDS, AWS S3 and PDF file\n",
    "2. Clean each extracted data\n",
    "3. Push the cleaned data as tables to a database\n",
    "4. Create the star-schema model in your database\n",
    "5. Query the database for sales analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Prerequisites\n",
    "\n",
    "- <b>OOP:</b> Classes, methods and functions.\n",
    "- <b>Pandas:</b> Reading from data sources, cleaning data and pushing data to a database\n",
    "- <b>AWS:</b> boto3 for code and CLI for configuration\n",
    "- <b>SQL:</b> For creating data model and querying the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other prerequisites\n",
    "\n",
    "- <b>APIs:</b> For extracting the stores data\n",
    "- <b>tabula</b> (and installation + configuration of Java): For extracting the credit card data in PDF file\n",
    "- <b>Data and file types:</b> YAML, JSON, CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software needed\n",
    "\n",
    "- <b>VSCode:</b> IDE (Integrated Development Environment)\n",
    "- <b>Conda:</b> Package manager\n",
    "- <b>pgAdmin4 or SQLTools:</b> Interface for PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from class_1_data_extractor import DataExtractor\n",
    "from class_2_database_connector import DatabaseConnector\n",
    "from class_3_data_cleaning import DataCleaning\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the RDS Database and Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database engine initialized successfully.\n",
      "Tables in the database: ['legacy_store_details', 'dim_card_details', 'legacy_users', 'orders_table']\n",
      "Data before cleaning:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>company</th>\n",
       "      <th>email_address</th>\n",
       "      <th>address</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>join_date</th>\n",
       "      <th>user_uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sigfried</td>\n",
       "      <td>Noack</td>\n",
       "      <td>1990-09-30</td>\n",
       "      <td>Heydrich Junitz KG</td>\n",
       "      <td>rudi79@winkler.de</td>\n",
       "      <td>Zimmerstr. 1/0\\n59015 Gießen</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "      <td>+49(0) 047905356</td>\n",
       "      <td>2018-10-10</td>\n",
       "      <td>93caf182-e4e9-4c6e-bebb-60a1a9dcf9b8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Guy</td>\n",
       "      <td>Allen</td>\n",
       "      <td>1940-12-01</td>\n",
       "      <td>Fox Ltd</td>\n",
       "      <td>rhodesclifford@henderson.com</td>\n",
       "      <td>Studio 22a\\nLynne terrace\\nMcCarthymouth\\nTF0 9GH</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>(0161) 496 0674</td>\n",
       "      <td>2001-12-20</td>\n",
       "      <td>8fe96c3a-d62d-4eb5-b313-cf12d9126a49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Harry</td>\n",
       "      <td>Lawrence</td>\n",
       "      <td>1995-08-02</td>\n",
       "      <td>Johnson, Jones and Harris</td>\n",
       "      <td>glen98@bryant-marshall.co.uk</td>\n",
       "      <td>92 Ann drive\\nJoanborough\\nSK0 6LR</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>+44(0)121 4960340</td>\n",
       "      <td>2016-12-16</td>\n",
       "      <td>fc461df4-b919-48b2-909e-55c95a03fe6b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Darren</td>\n",
       "      <td>Hussain</td>\n",
       "      <td>1972-09-23</td>\n",
       "      <td>Wheeler LLC</td>\n",
       "      <td>daniellebryan@thompson.org</td>\n",
       "      <td>19 Robinson meadow\\nNew Tracy\\nW22 2QG</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>(0306) 999 0871</td>\n",
       "      <td>2004-02-23</td>\n",
       "      <td>6104719f-ef14-4b09-bf04-fb0c4620acb0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Garry</td>\n",
       "      <td>Stone</td>\n",
       "      <td>1952-12-20</td>\n",
       "      <td>Warner Inc</td>\n",
       "      <td>billy14@long-warren.com</td>\n",
       "      <td>3 White pass\\nHunterborough\\nNN96 4UE</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>0121 496 0225</td>\n",
       "      <td>2006-09-01</td>\n",
       "      <td>9523a6d3-b2dd-4670-a51a-36aebc89f579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index first_name last_name date_of_birth                    company  \\\n",
       "0      0   Sigfried     Noack    1990-09-30         Heydrich Junitz KG   \n",
       "1      1        Guy     Allen    1940-12-01                    Fox Ltd   \n",
       "2      2      Harry  Lawrence    1995-08-02  Johnson, Jones and Harris   \n",
       "3      3     Darren   Hussain    1972-09-23                Wheeler LLC   \n",
       "4      4      Garry     Stone    1952-12-20                 Warner Inc   \n",
       "\n",
       "                  email_address  \\\n",
       "0             rudi79@winkler.de   \n",
       "1  rhodesclifford@henderson.com   \n",
       "2  glen98@bryant-marshall.co.uk   \n",
       "3    daniellebryan@thompson.org   \n",
       "4       billy14@long-warren.com   \n",
       "\n",
       "                                             address         country  \\\n",
       "0                       Zimmerstr. 1/0\\n59015 Gießen         Germany   \n",
       "1  Studio 22a\\nLynne terrace\\nMcCarthymouth\\nTF0 9GH  United Kingdom   \n",
       "2                 92 Ann drive\\nJoanborough\\nSK0 6LR  United Kingdom   \n",
       "3             19 Robinson meadow\\nNew Tracy\\nW22 2QG  United Kingdom   \n",
       "4              3 White pass\\nHunterborough\\nNN96 4UE  United Kingdom   \n",
       "\n",
       "  country_code       phone_number   join_date  \\\n",
       "0           DE   +49(0) 047905356  2018-10-10   \n",
       "1           GB    (0161) 496 0674  2001-12-20   \n",
       "2           GB  +44(0)121 4960340  2016-12-16   \n",
       "3           GB    (0306) 999 0871  2004-02-23   \n",
       "4           GB      0121 496 0225  2006-09-01   \n",
       "\n",
       "                              user_uuid  \n",
       "0  93caf182-e4e9-4c6e-bebb-60a1a9dcf9b8  \n",
       "1  8fe96c3a-d62d-4eb5-b313-cf12d9126a49  \n",
       "2  fc461df4-b919-48b2-909e-55c95a03fe6b  \n",
       "3  6104719f-ef14-4b09-bf04-fb0c4620acb0  \n",
       "4  9523a6d3-b2dd-4670-a51a-36aebc89f579  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as 'legacy_dim_users.csv'\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Connect to the RDS Database\n",
    "rds_db_connector = DatabaseConnector(config_path='aws_db_creds.yaml')\n",
    "\n",
    "# Step 2: Extract Data from RDS\n",
    "data_extractor = DataExtractor(rds_db_connector)\n",
    "tables = data_extractor.list_tables()\n",
    "\n",
    "# Specify the table you want to clean\n",
    "target_table = 'legacy_users'\n",
    "\n",
    "if target_table in tables:\n",
    "    df = data_extractor.read_rds_table(target_table)\n",
    "    if df is not None:\n",
    "        print(\"Data before cleaning:\")\n",
    "        display(df.head())  # Use display to render the DataFrame nicely in Jupyter\n",
    "        # Save the DataFrame as 'legacy_dim_users'\n",
    "        df.to_csv('legacy_dim_users.csv', index=False)\n",
    "        print(\"DataFrame saved as 'legacy_dim_users.csv'\")\n",
    "    else:\n",
    "        print(\"Failed to extract the table data\")\n",
    "else:\n",
    "    print(f\"Table {target_table} not found in the database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after cleaning:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c5/5hv48d2x71q5swk5cwj45zy40000gn/T/ipykernel_39827/4085258179.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  cleaned_df = cleaned_df.applymap(lambda x: re.sub(r',\\s*', ', ', x) if isinstance(x, str) else x)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>company</th>\n",
       "      <th>email_address</th>\n",
       "      <th>address</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>join_date</th>\n",
       "      <th>user_uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sigfried</td>\n",
       "      <td>Noack</td>\n",
       "      <td>1990-09-30</td>\n",
       "      <td>Heydrich Junitz KG</td>\n",
       "      <td>rudi79@winkler.de</td>\n",
       "      <td>Zimmerstr. 1/0, 59015 Gießen</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "      <td>490047905356</td>\n",
       "      <td>2018-10-10</td>\n",
       "      <td>93caf182-e4e9-4c6e-bebb-60a1a9dcf9b8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Guy</td>\n",
       "      <td>Allen</td>\n",
       "      <td>1940-12-01</td>\n",
       "      <td>Fox Ltd</td>\n",
       "      <td>rhodesclifford@henderson.com</td>\n",
       "      <td>Studio 22a, Lynne terrace, McCarthymouth, TF0 9GH</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>01614960674</td>\n",
       "      <td>2001-12-20</td>\n",
       "      <td>8fe96c3a-d62d-4eb5-b313-cf12d9126a49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Harry</td>\n",
       "      <td>Lawrence</td>\n",
       "      <td>1995-08-02</td>\n",
       "      <td>Johnson, Jones and Harris</td>\n",
       "      <td>glen98@bryant-marshall.co.uk</td>\n",
       "      <td>92 Ann drive, Joanborough, SK0 6LR</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>4401214960340</td>\n",
       "      <td>2016-12-16</td>\n",
       "      <td>fc461df4-b919-48b2-909e-55c95a03fe6b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Darren</td>\n",
       "      <td>Hussain</td>\n",
       "      <td>1972-09-23</td>\n",
       "      <td>Wheeler LLC</td>\n",
       "      <td>daniellebryan@thompson.org</td>\n",
       "      <td>19 Robinson meadow, New Tracy, W22 2QG</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>03069990871</td>\n",
       "      <td>2004-02-23</td>\n",
       "      <td>6104719f-ef14-4b09-bf04-fb0c4620acb0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Garry</td>\n",
       "      <td>Stone</td>\n",
       "      <td>1952-12-20</td>\n",
       "      <td>Warner Inc</td>\n",
       "      <td>billy14@long-warren.com</td>\n",
       "      <td>3 White pass, Hunterborough, NN96 4UE</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>01214960225</td>\n",
       "      <td>2006-09-01</td>\n",
       "      <td>9523a6d3-b2dd-4670-a51a-36aebc89f579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index first_name last_name date_of_birth                    company  \\\n",
       "0      0   Sigfried     Noack    1990-09-30         Heydrich Junitz KG   \n",
       "1      1        Guy     Allen    1940-12-01                    Fox Ltd   \n",
       "2      2      Harry  Lawrence    1995-08-02  Johnson, Jones and Harris   \n",
       "3      3     Darren   Hussain    1972-09-23                Wheeler LLC   \n",
       "4      4      Garry     Stone    1952-12-20                 Warner Inc   \n",
       "\n",
       "                  email_address  \\\n",
       "0             rudi79@winkler.de   \n",
       "1  rhodesclifford@henderson.com   \n",
       "2  glen98@bryant-marshall.co.uk   \n",
       "3    daniellebryan@thompson.org   \n",
       "4       billy14@long-warren.com   \n",
       "\n",
       "                                             address         country  \\\n",
       "0                       Zimmerstr. 1/0, 59015 Gießen         Germany   \n",
       "1  Studio 22a, Lynne terrace, McCarthymouth, TF0 9GH  United Kingdom   \n",
       "2                 92 Ann drive, Joanborough, SK0 6LR  United Kingdom   \n",
       "3             19 Robinson meadow, New Tracy, W22 2QG  United Kingdom   \n",
       "4              3 White pass, Hunterborough, NN96 4UE  United Kingdom   \n",
       "\n",
       "  country_code   phone_number  join_date                             user_uuid  \n",
       "0           DE   490047905356 2018-10-10  93caf182-e4e9-4c6e-bebb-60a1a9dcf9b8  \n",
       "1           GB    01614960674 2001-12-20  8fe96c3a-d62d-4eb5-b313-cf12d9126a49  \n",
       "2           GB  4401214960340 2016-12-16  fc461df4-b919-48b2-909e-55c95a03fe6b  \n",
       "3           GB    03069990871 2004-02-23  6104719f-ef14-4b09-bf04-fb0c4620acb0  \n",
       "4           GB    01214960225 2006-09-01  9523a6d3-b2dd-4670-a51a-36aebc89f579  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'df' in locals():\n",
    "    # Step 3: Clean the Data\n",
    "    data_cleaner = DataCleaning()\n",
    "    cleaned_df = data_cleaner.clean_user_data(df)\n",
    "    cleaned_df = cleaned_df.applymap(lambda x: re.sub(r',\\s*', ', ', x) if isinstance(x, str) else x)\n",
    "    print(\"Data after cleaning:\")\n",
    "    display(cleaned_df.head())  # Use display to render the DataFrame nicely in Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Local Database and Upload the Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database engine initialized successfully.\n",
      "Data uploaded to table dim_users successfully.\n",
      "Data uploaded to the local database as 'dim_users'\n",
      "Data uploaded to table legacy_dim_users successfully.\n",
      "Legend data uploaded to the local database as 'legacy_dim_users'\n"
     ]
    }
   ],
   "source": [
    "if 'cleaned_df' in locals():\n",
    "    # Step 4: Connect to the Local Database\n",
    "    local_db_connector = DatabaseConnector(config_path='local_db_creds.yaml')\n",
    "\n",
    "    # Step 5: Upload the cleaned data to the local database as 'dim_users'\n",
    "    local_db_connector.upload_to_db(cleaned_df, \"dim_users\")\n",
    "    print(\"Data uploaded to the local database as 'dim_users'\")\n",
    "\n",
    "    # Upload the legacy_dim_users dataframe\n",
    "    legend_dim_users = pd.read_csv('legacy_dim_users.csv')\n",
    "    local_db_connector.upload_to_db(legend_dim_users, \"legacy_dim_users\")\n",
    "    print(\"Legend data uploaded to the local database as 'legacy_dim_users'\")\n",
    "else:\n",
    "    print(\"Cleaned DataFrame not found, cannot upload to the database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Data from the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to import jpype dependencies. Fallback to subprocess.\n",
      "No module named 'jpype'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after extraction and attempted conversion:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_number</th>\n",
       "      <th>expiry_date</th>\n",
       "      <th>card_provider</th>\n",
       "      <th>date_payment_confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30060773296197</td>\n",
       "      <td>09/26</td>\n",
       "      <td>Diners Club / Carte Blanche</td>\n",
       "      <td>2015-11-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>349624180933183</td>\n",
       "      <td>10/23</td>\n",
       "      <td>American Express</td>\n",
       "      <td>2001-06-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3529023891650490</td>\n",
       "      <td>06/23</td>\n",
       "      <td>JCB 16 digit</td>\n",
       "      <td>2000-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>213142929492281</td>\n",
       "      <td>09/27</td>\n",
       "      <td>JCB 15 digit</td>\n",
       "      <td>2011-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>502067329974</td>\n",
       "      <td>10/25</td>\n",
       "      <td>Maestro</td>\n",
       "      <td>1997-03-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        card_number expiry_date                card_provider  \\\n",
       "0    30060773296197       09/26  Diners Club / Carte Blanche   \n",
       "1   349624180933183       10/23             American Express   \n",
       "2  3529023891650490       06/23                 JCB 16 digit   \n",
       "3   213142929492281       09/27                 JCB 15 digit   \n",
       "4      502067329974       10/25                      Maestro   \n",
       "\n",
       "  date_payment_confirmed  \n",
       "0             2015-11-25  \n",
       "1             2001-06-18  \n",
       "2             2000-12-26  \n",
       "3             2011-02-12  \n",
       "4             1997-03-13  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as 'legacy_dim_card_details.csv'\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Retrieve data from the PDF\n",
    "pdf_link = \"https://data-handling-public.s3.eu-west-1.amazonaws.com/card_details.pdf\"\n",
    "data_extractor = DataExtractor()\n",
    "\n",
    "# Extract data from the PDF\n",
    "pdf_data_df = data_extractor.retrieve_pdf_data(pdf_link)\n",
    "\n",
    "if not pdf_data_df.empty:\n",
    "    print(\"Data after extraction and attempted conversion:\")\n",
    "    display(pdf_data_df.head())  # Assuming you are in Jupyter, this will nicely render the DataFrame\n",
    "else:\n",
    "    print(\"Failed to retrieve data from the PDF.\")\n",
    "\n",
    "# Save the DataFrame as 'legacy_dim_card_details'\n",
    "pdf_data_df.to_csv('legacy_dim_card_details.csv', index=False)\n",
    "print(\"DataFrame saved as 'legacy_dim_card_details.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardise Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after standardizing nulls:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_number</th>\n",
       "      <th>expiry_date</th>\n",
       "      <th>card_provider</th>\n",
       "      <th>date_payment_confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30060773296197</td>\n",
       "      <td>09/26</td>\n",
       "      <td>Diners Club / Carte Blanche</td>\n",
       "      <td>2015-11-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>349624180933183</td>\n",
       "      <td>10/23</td>\n",
       "      <td>American Express</td>\n",
       "      <td>2001-06-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3529023891650490</td>\n",
       "      <td>06/23</td>\n",
       "      <td>JCB 16 digit</td>\n",
       "      <td>2000-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>213142929492281</td>\n",
       "      <td>09/27</td>\n",
       "      <td>JCB 15 digit</td>\n",
       "      <td>2011-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>502067329974</td>\n",
       "      <td>10/25</td>\n",
       "      <td>Maestro</td>\n",
       "      <td>1997-03-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        card_number expiry_date                card_provider  \\\n",
       "0    30060773296197       09/26  Diners Club / Carte Blanche   \n",
       "1   349624180933183       10/23             American Express   \n",
       "2  3529023891650490       06/23                 JCB 16 digit   \n",
       "3   213142929492281       09/27                 JCB 15 digit   \n",
       "4      502067329974       10/25                      Maestro   \n",
       "\n",
       "  date_payment_confirmed  \n",
       "0             2015-11-25  \n",
       "1             2001-06-18  \n",
       "2             2000-12-26  \n",
       "3             2011-02-12  \n",
       "4             1997-03-13  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 2.1: Standardize Nulls\n",
    "if 'pdf_data_df' in locals():\n",
    "    data_cleaner = DataCleaning()\n",
    "    cleaned_df = data_cleaner.standardize_nulls(pdf_data_df)\n",
    "    print(\"Data after standardizing nulls:\")\n",
    "    display(cleaned_df.head())\n",
    "else:\n",
    "    print(\"Data extraction failed, cannot proceed with cleaning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Card Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after cleaning card numbers:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_number</th>\n",
       "      <th>expiry_date</th>\n",
       "      <th>card_provider</th>\n",
       "      <th>date_payment_confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30060773296197</td>\n",
       "      <td>09/26</td>\n",
       "      <td>Diners Club / Carte Blanche</td>\n",
       "      <td>2015-11-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>349624180933183</td>\n",
       "      <td>10/23</td>\n",
       "      <td>American Express</td>\n",
       "      <td>2001-06-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3529023891650490</td>\n",
       "      <td>06/23</td>\n",
       "      <td>JCB 16 digit</td>\n",
       "      <td>2000-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>213142929492281</td>\n",
       "      <td>09/27</td>\n",
       "      <td>JCB 15 digit</td>\n",
       "      <td>2011-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>502067329974</td>\n",
       "      <td>10/25</td>\n",
       "      <td>Maestro</td>\n",
       "      <td>1997-03-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        card_number expiry_date                card_provider  \\\n",
       "0    30060773296197       09/26  Diners Club / Carte Blanche   \n",
       "1   349624180933183       10/23             American Express   \n",
       "2  3529023891650490       06/23                 JCB 16 digit   \n",
       "3   213142929492281       09/27                 JCB 15 digit   \n",
       "4      502067329974       10/25                      Maestro   \n",
       "\n",
       "  date_payment_confirmed  \n",
       "0             2015-11-25  \n",
       "1             2001-06-18  \n",
       "2             2000-12-26  \n",
       "3             2011-02-12  \n",
       "4             1997-03-13  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 2.2: Clean Card Numbers\n",
    "if 'cleaned_df' in locals():\n",
    "    cleaned_df = data_cleaner.clean_card_number(cleaned_df)\n",
    "    print(\"Data after cleaning card numbers:\")\n",
    "    display(cleaned_df.head())\n",
    "else:\n",
    "    print(\"Standardized null data not available, cannot proceed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after cleaning dates:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_number</th>\n",
       "      <th>expiry_date</th>\n",
       "      <th>card_provider</th>\n",
       "      <th>date_payment_confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30060773296197</td>\n",
       "      <td>09/26</td>\n",
       "      <td>Diners Club / Carte Blanche</td>\n",
       "      <td>2015-11-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>349624180933183</td>\n",
       "      <td>10/23</td>\n",
       "      <td>American Express</td>\n",
       "      <td>2001-06-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3529023891650490</td>\n",
       "      <td>06/23</td>\n",
       "      <td>JCB 16 digit</td>\n",
       "      <td>2000-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>213142929492281</td>\n",
       "      <td>09/27</td>\n",
       "      <td>JCB 15 digit</td>\n",
       "      <td>2011-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>502067329974</td>\n",
       "      <td>10/25</td>\n",
       "      <td>Maestro</td>\n",
       "      <td>1997-03-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        card_number expiry_date                card_provider  \\\n",
       "0    30060773296197       09/26  Diners Club / Carte Blanche   \n",
       "1   349624180933183       10/23             American Express   \n",
       "2  3529023891650490       06/23                 JCB 16 digit   \n",
       "3   213142929492281       09/27                 JCB 15 digit   \n",
       "4      502067329974       10/25                      Maestro   \n",
       "\n",
       "  date_payment_confirmed  \n",
       "0             2015-11-25  \n",
       "1             2001-06-18  \n",
       "2             2000-12-26  \n",
       "3             2011-02-12  \n",
       "4             1997-03-13  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 2.3: Clean Dates\n",
    "if 'cleaned_df' in locals():\n",
    "    cleaned_df = data_cleaner.clean_dates(cleaned_df, date_columns=['date_payment_confirmed'])\n",
    "    print(\"Data after cleaning dates:\")\n",
    "    display(cleaned_df.head())\n",
    "else:\n",
    "    print(\"Card numbers not cleaned, cannot proceed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Invalid Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after removing invalid rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_number</th>\n",
       "      <th>expiry_date</th>\n",
       "      <th>card_provider</th>\n",
       "      <th>date_payment_confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30060773296197</td>\n",
       "      <td>09/26</td>\n",
       "      <td>Diners Club / Carte Blanche</td>\n",
       "      <td>2015-11-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>349624180933183</td>\n",
       "      <td>10/23</td>\n",
       "      <td>American Express</td>\n",
       "      <td>2001-06-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3529023891650490</td>\n",
       "      <td>06/23</td>\n",
       "      <td>JCB 16 digit</td>\n",
       "      <td>2000-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>213142929492281</td>\n",
       "      <td>09/27</td>\n",
       "      <td>JCB 15 digit</td>\n",
       "      <td>2011-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>502067329974</td>\n",
       "      <td>10/25</td>\n",
       "      <td>Maestro</td>\n",
       "      <td>1997-03-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        card_number expiry_date                card_provider  \\\n",
       "0    30060773296197       09/26  Diners Club / Carte Blanche   \n",
       "1   349624180933183       10/23             American Express   \n",
       "2  3529023891650490       06/23                 JCB 16 digit   \n",
       "3   213142929492281       09/27                 JCB 15 digit   \n",
       "4      502067329974       10/25                      Maestro   \n",
       "\n",
       "  date_payment_confirmed  \n",
       "0             2015-11-25  \n",
       "1             2001-06-18  \n",
       "2             2000-12-26  \n",
       "3             2011-02-12  \n",
       "4             1997-03-13  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 2.4: Remove Invalid Rows\n",
    "if 'cleaned_df' in locals():\n",
    "    cleaned_df = data_cleaner.remove_invalid_rows(cleaned_df)\n",
    "    print(\"Data after removing invalid rows:\")\n",
    "    display(cleaned_df.head())\n",
    "else:\n",
    "    print(\"Date cleaning not performed, cannot proceed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final cleaned data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_number</th>\n",
       "      <th>expiry_date</th>\n",
       "      <th>card_provider</th>\n",
       "      <th>date_payment_confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30060773296197</td>\n",
       "      <td>09/26</td>\n",
       "      <td>Diners Club / Carte Blanche</td>\n",
       "      <td>2015-11-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>349624180933183</td>\n",
       "      <td>10/23</td>\n",
       "      <td>American Express</td>\n",
       "      <td>2001-06-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3529023891650490</td>\n",
       "      <td>06/23</td>\n",
       "      <td>JCB 16 digit</td>\n",
       "      <td>2000-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>213142929492281</td>\n",
       "      <td>09/27</td>\n",
       "      <td>JCB 15 digit</td>\n",
       "      <td>2011-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>502067329974</td>\n",
       "      <td>10/25</td>\n",
       "      <td>Maestro</td>\n",
       "      <td>1997-03-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        card_number expiry_date                card_provider  \\\n",
       "0    30060773296197       09/26  Diners Club / Carte Blanche   \n",
       "1   349624180933183       10/23             American Express   \n",
       "2  3529023891650490       06/23                 JCB 16 digit   \n",
       "3   213142929492281       09/27                 JCB 15 digit   \n",
       "4      502067329974       10/25                      Maestro   \n",
       "\n",
       "  date_payment_confirmed  \n",
       "0             2015-11-25  \n",
       "1             2001-06-18  \n",
       "2             2000-12-26  \n",
       "3             2011-02-12  \n",
       "4             1997-03-13  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display final cleaned data\n",
    "if 'cleaned_df' in locals():\n",
    "    print(\"Final cleaned data:\")\n",
    "    display(cleaned_df.head())\n",
    "else:\n",
    "    print(\"Invalid rows not removed, cannot proceed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Local Database and Upload Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database engine initialized successfully.\n",
      "Data uploaded to table dim_card_details successfully.\n",
      "Cleaned data uploaded to the local database as 'dim_card_details'\n",
      "Data uploaded to table legacy_dim_card_details successfully.\n",
      "Legend data uploaded to the local database as 'legacy_dim_card_details'\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Connect to Local Database\n",
    "if 'cleaned_df' in locals():\n",
    "    local_db_connector = DatabaseConnector(config_path='local_db_creds.yaml')\n",
    "\n",
    "    # Step 4: Upload cleaned data to local database\n",
    "    local_db_connector.upload_to_db(cleaned_df, \"dim_card_details\")\n",
    "    print(\"Cleaned data uploaded to the local database as 'dim_card_details'\")\n",
    "\n",
    "    # Upload the legacy_dim_card_details dataframe\n",
    "    legend_dim_card_details = pd.read_csv('legacy_dim_card_details.csv')\n",
    "    local_db_connector.upload_to_db(legend_dim_card_details, \"legacy_dim_card_details\")\n",
    "    print(\"Legend data uploaded to the local database as 'legacy_dim_card_details'\")\n",
    "else:\n",
    "    print(\"Cleaned data not available, cannot upload.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define API Details and Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define API details\n",
    "stores_endpoint = \"https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores\"\n",
    "store_details_endpoint = \"https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details\"\n",
    "headers = {\"x-api-key\": \"yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Instance of DataExtractor and Retrieve Number of Stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stores: 451\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Create an instance of DataExtractor\n",
    "data_extractor = DataExtractor()\n",
    "\n",
    "# Step 3: Retrieve the number of stores\n",
    "number_of_stores = data_extractor.list_number_of_stores(stores_endpoint, headers)\n",
    "print(f\"Number of stores: {number_of_stores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Stores Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for store number 451: 500 Server Error: Internal Server Error for url: https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/451\n",
      "Data before cleaning:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>address</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lat</th>\n",
       "      <th>locality</th>\n",
       "      <th>store_code</th>\n",
       "      <th>staff_numbers</th>\n",
       "      <th>opening_date</th>\n",
       "      <th>store_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>country_code</th>\n",
       "      <th>continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Flat 72W\\nSally isle\\nEast Deantown\\nE7B 8EB, ...</td>\n",
       "      <td>51.62907</td>\n",
       "      <td>None</td>\n",
       "      <td>High Wycombe</td>\n",
       "      <td>HI-9B97EE4E</td>\n",
       "      <td>34</td>\n",
       "      <td>1996-10-25</td>\n",
       "      <td>Local</td>\n",
       "      <td>-0.74934</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Heckerstraße 4/5\\n50491 Säckingen, Landshut</td>\n",
       "      <td>48.52961</td>\n",
       "      <td>None</td>\n",
       "      <td>Landshut</td>\n",
       "      <td>LA-0772C7B9</td>\n",
       "      <td>92</td>\n",
       "      <td>2013-04-12</td>\n",
       "      <td>Super Store</td>\n",
       "      <td>12.16179</td>\n",
       "      <td>DE</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5 Harrison tunnel\\nSouth Lydia\\nWC9 2BE, Westbury</td>\n",
       "      <td>51.26</td>\n",
       "      <td>None</td>\n",
       "      <td>Westbury</td>\n",
       "      <td>WE-1DE82CEE</td>\n",
       "      <td>69</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>Super Store</td>\n",
       "      <td>-2.1875</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Studio 6\\nStephen landing\\nSouth Simon\\nB77 2W...</td>\n",
       "      <td>53.0233</td>\n",
       "      <td>None</td>\n",
       "      <td>Belper</td>\n",
       "      <td>BE-18074576</td>\n",
       "      <td>35</td>\n",
       "      <td>2019-09-09</td>\n",
       "      <td>Local</td>\n",
       "      <td>-1.48119</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Flat 92u\\nChristian harbors\\nPort Charlotte\\nN...</td>\n",
       "      <td>53.38333</td>\n",
       "      <td>None</td>\n",
       "      <td>Gainsborough</td>\n",
       "      <td>GA-CAD01AC2</td>\n",
       "      <td>36</td>\n",
       "      <td>1995-05-15</td>\n",
       "      <td>Local</td>\n",
       "      <td>-0.76667</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            address longitude   lat  \\\n",
       "0      1  Flat 72W\\nSally isle\\nEast Deantown\\nE7B 8EB, ...  51.62907  None   \n",
       "1      2        Heckerstraße 4/5\\n50491 Säckingen, Landshut  48.52961  None   \n",
       "2      3  5 Harrison tunnel\\nSouth Lydia\\nWC9 2BE, Westbury     51.26  None   \n",
       "3      4  Studio 6\\nStephen landing\\nSouth Simon\\nB77 2W...   53.0233  None   \n",
       "4      5  Flat 92u\\nChristian harbors\\nPort Charlotte\\nN...  53.38333  None   \n",
       "\n",
       "       locality   store_code staff_numbers opening_date   store_type  \\\n",
       "0  High Wycombe  HI-9B97EE4E            34   1996-10-25        Local   \n",
       "1      Landshut  LA-0772C7B9            92   2013-04-12  Super Store   \n",
       "2      Westbury  WE-1DE82CEE            69   2014-01-02  Super Store   \n",
       "3        Belper  BE-18074576            35   2019-09-09        Local   \n",
       "4  Gainsborough  GA-CAD01AC2            36   1995-05-15        Local   \n",
       "\n",
       "   latitude country_code continent  \n",
       "0  -0.74934           GB    Europe  \n",
       "1  12.16179           DE    Europe  \n",
       "2   -2.1875           GB    Europe  \n",
       "3  -1.48119           GB    Europe  \n",
       "4  -0.76667           GB    Europe  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as 'legacy_dim_store_details.csv'\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Retrieve stores data\n",
    "if number_of_stores:\n",
    "    stores_df = data_extractor.retrieve_stores_data(store_details_endpoint, headers, number_of_stores)\n",
    "    if stores_df is not None:\n",
    "        print(\"Data before cleaning:\")\n",
    "        display(stores_df.head())  # Use display to render the DataFrame in Jupyter\n",
    "        \n",
    "        # Save the DataFrame as 'legacy_dim_store_details'\n",
    "        stores_df.to_csv('legacy_dim_store_details.csv', index=False)\n",
    "        print(\"DataFrame saved as 'legacy_dim_store_details.csv'\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve stores data.\")\n",
    "else:\n",
    "    print(\"Failed to retrieve number of stores.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after cleaning:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c5/5hv48d2x71q5swk5cwj45zy40000gn/T/ipykernel_39827/3638795891.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  cleaned_df = cleaned_df.applymap(lambda x: re.sub(r',\\s*', ', ', x) if isinstance(x, str) else x)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>address</th>\n",
       "      <th>longitude</th>\n",
       "      <th>locality</th>\n",
       "      <th>store_code</th>\n",
       "      <th>staff_numbers</th>\n",
       "      <th>opening_date</th>\n",
       "      <th>store_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>country_code</th>\n",
       "      <th>continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Flat 72W, Sally isle, East Deantown, E7B 8EB, ...</td>\n",
       "      <td>51.62907</td>\n",
       "      <td>High Wycombe</td>\n",
       "      <td>HI-9B97EE4E</td>\n",
       "      <td>34</td>\n",
       "      <td>1996-10-25</td>\n",
       "      <td>Local</td>\n",
       "      <td>-0.74934</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Heckerstraße 4/5, 50491 Säckingen, Landshut</td>\n",
       "      <td>48.52961</td>\n",
       "      <td>Landshut</td>\n",
       "      <td>LA-0772C7B9</td>\n",
       "      <td>92</td>\n",
       "      <td>2013-04-12</td>\n",
       "      <td>Super Store</td>\n",
       "      <td>12.16179</td>\n",
       "      <td>DE</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5 Harrison tunnel, South Lydia, WC9 2BE, Westbury</td>\n",
       "      <td>51.26</td>\n",
       "      <td>Westbury</td>\n",
       "      <td>WE-1DE82CEE</td>\n",
       "      <td>69</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>Super Store</td>\n",
       "      <td>-2.1875</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Studio 6, Stephen landing, South Simon, B77 2W...</td>\n",
       "      <td>53.0233</td>\n",
       "      <td>Belper</td>\n",
       "      <td>BE-18074576</td>\n",
       "      <td>35</td>\n",
       "      <td>2019-09-09</td>\n",
       "      <td>Local</td>\n",
       "      <td>-1.48119</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Flat 92u, Christian harbors, Port Charlotte, N...</td>\n",
       "      <td>53.38333</td>\n",
       "      <td>Gainsborough</td>\n",
       "      <td>GA-CAD01AC2</td>\n",
       "      <td>36</td>\n",
       "      <td>1995-05-15</td>\n",
       "      <td>Local</td>\n",
       "      <td>-0.76667</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            address longitude  \\\n",
       "0      1  Flat 72W, Sally isle, East Deantown, E7B 8EB, ...  51.62907   \n",
       "1      2        Heckerstraße 4/5, 50491 Säckingen, Landshut  48.52961   \n",
       "2      3  5 Harrison tunnel, South Lydia, WC9 2BE, Westbury     51.26   \n",
       "3      4  Studio 6, Stephen landing, South Simon, B77 2W...   53.0233   \n",
       "4      5  Flat 92u, Christian harbors, Port Charlotte, N...  53.38333   \n",
       "\n",
       "       locality   store_code staff_numbers opening_date   store_type  \\\n",
       "0  High Wycombe  HI-9B97EE4E            34   1996-10-25        Local   \n",
       "1      Landshut  LA-0772C7B9            92   2013-04-12  Super Store   \n",
       "2      Westbury  WE-1DE82CEE            69   2014-01-02  Super Store   \n",
       "3        Belper  BE-18074576            35   2019-09-09        Local   \n",
       "4  Gainsborough  GA-CAD01AC2            36   1995-05-15        Local   \n",
       "\n",
       "   latitude country_code continent  \n",
       "0  -0.74934           GB    Europe  \n",
       "1  12.16179           DE    Europe  \n",
       "2   -2.1875           GB    Europe  \n",
       "3  -1.48119           GB    Europe  \n",
       "4  -0.76667           GB    Europe  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 447 out of 441.\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Clean the Data\n",
    "if 'stores_df' in locals():\n",
    "    data_cleaner = DataCleaning()\n",
    "    cleaned_df = data_cleaner.clean_store_details(stores_df)\n",
    "    cleaned_df = cleaned_df.applymap(lambda x: re.sub(r',\\s*', ', ', x) if isinstance(x, str) else x)\n",
    "\n",
    "    # Step 6: Display the cleaned data\n",
    "    print(\"Data after cleaning:\")\n",
    "    display(cleaned_df.head())\n",
    "else:\n",
    "    print(\"Stores DataFrame not available, cannot proceed with cleaning.\")\n",
    "\n",
    "# Print the total number of rows\n",
    "print(f\"Total number of rows: {cleaned_df.shape[0]} out of 441.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Local Database and Upload Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database engine initialized successfully.\n",
      "Data uploaded to table dim_store_details successfully.\n",
      "Cleaned data uploaded to the local database as 'dim_store_details'\n",
      "Data uploaded to table legacy_dim_store_details successfully.\n",
      "Legend data uploaded to the local database as 'legacy_dim_store_details'\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Connect to the Local Database\n",
    "if 'cleaned_df' in locals():\n",
    "    local_db_connector = DatabaseConnector(config_path='local_db_creds.yaml')\n",
    "\n",
    "    # Step 8: Upload the cleaned data to the local database\n",
    "    local_db_connector.upload_to_db(cleaned_df, \"dim_store_details\")\n",
    "    print(\"Cleaned data uploaded to the local database as 'dim_store_details'\")\n",
    "\n",
    "    # Upload the legacy_dim_store_details dataframe\n",
    "    legend_dim_store_details = pd.read_csv('legacy_dim_store_details.csv')\n",
    "    local_db_connector.upload_to_db(legend_dim_store_details, \"legacy_dim_store_details\")\n",
    "    print(\"Legend data uploaded to the local database as 'legacy_dim_store_details'\")\n",
    "else:\n",
    "    print(\"Cleaned data not available, cannot upload.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define S3 URI and Create DataExtractor Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define S3 URI\n",
    "s3_uri = 's3://data-handling-public/products.csv'\n",
    "\n",
    "# Step 2: Create an instance of DataExtractor\n",
    "data_extractor = DataExtractor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Product Data from S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data before cleaning:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "      <th>weight</th>\n",
       "      <th>category</th>\n",
       "      <th>EAN</th>\n",
       "      <th>date_added</th>\n",
       "      <th>uuid</th>\n",
       "      <th>removed</th>\n",
       "      <th>product_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FurReal Dazzlin' Dimples My Playful Dolphin</td>\n",
       "      <td>£39.99</td>\n",
       "      <td>1.6kg</td>\n",
       "      <td>toys-and-games</td>\n",
       "      <td>7425710935115</td>\n",
       "      <td>2005-12-02</td>\n",
       "      <td>83dc0a69-f96f-4c34-bcb7-928acae19a94</td>\n",
       "      <td>Still_avaliable</td>\n",
       "      <td>R7-3126933h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Tiffany's World Day Out At The Park</td>\n",
       "      <td>£12.99</td>\n",
       "      <td>0.48kg</td>\n",
       "      <td>toys-and-games</td>\n",
       "      <td>487128731892</td>\n",
       "      <td>2006-01-09</td>\n",
       "      <td>712254d7-aea7-4310-aff8-8bcdd0aec7ff</td>\n",
       "      <td>Still_avaliable</td>\n",
       "      <td>C2-7287916l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Tiffany's World Pups Picnic Playset</td>\n",
       "      <td>£7.00</td>\n",
       "      <td>590g</td>\n",
       "      <td>toys-and-games</td>\n",
       "      <td>1945816904649</td>\n",
       "      <td>1997-03-29</td>\n",
       "      <td>b089ef6f-b628-4e37-811d-fffe0102ba64</td>\n",
       "      <td>Still_avaliable</td>\n",
       "      <td>S7-1175877v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Tiffany's World Wildlife Park Adventures</td>\n",
       "      <td>£12.99</td>\n",
       "      <td>540g</td>\n",
       "      <td>toys-and-games</td>\n",
       "      <td>1569790890899</td>\n",
       "      <td>2013-03-20</td>\n",
       "      <td>d55de422-8b98-47d6-9991-e4bc4c5c0cb0</td>\n",
       "      <td>Removed</td>\n",
       "      <td>D8-8421505n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Cosatto Cosy Dolls Pram</td>\n",
       "      <td>£30.00</td>\n",
       "      <td>1.91kg</td>\n",
       "      <td>toys-and-games</td>\n",
       "      <td>7142740213920</td>\n",
       "      <td>2007-12-23</td>\n",
       "      <td>7945b657-cb02-4cc5-96cf-f65ed0a8f235</td>\n",
       "      <td>Still_avaliable</td>\n",
       "      <td>B6-2596063a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                 product_name product_price  \\\n",
       "0           0  FurReal Dazzlin' Dimples My Playful Dolphin        £39.99   \n",
       "1           1          Tiffany's World Day Out At The Park        £12.99   \n",
       "2           2          Tiffany's World Pups Picnic Playset         £7.00   \n",
       "3           3     Tiffany's World Wildlife Park Adventures        £12.99   \n",
       "4           4                      Cosatto Cosy Dolls Pram        £30.00   \n",
       "\n",
       "   weight        category            EAN  date_added  \\\n",
       "0   1.6kg  toys-and-games  7425710935115  2005-12-02   \n",
       "1  0.48kg  toys-and-games   487128731892  2006-01-09   \n",
       "2    590g  toys-and-games  1945816904649  1997-03-29   \n",
       "3    540g  toys-and-games  1569790890899  2013-03-20   \n",
       "4  1.91kg  toys-and-games  7142740213920  2007-12-23   \n",
       "\n",
       "                                   uuid          removed product_code  \n",
       "0  83dc0a69-f96f-4c34-bcb7-928acae19a94  Still_avaliable  R7-3126933h  \n",
       "1  712254d7-aea7-4310-aff8-8bcdd0aec7ff  Still_avaliable  C2-7287916l  \n",
       "2  b089ef6f-b628-4e37-811d-fffe0102ba64  Still_avaliable  S7-1175877v  \n",
       "3  d55de422-8b98-47d6-9991-e4bc4c5c0cb0          Removed  D8-8421505n  \n",
       "4  7945b657-cb02-4cc5-96cf-f65ed0a8f235  Still_avaliable  B6-2596063a  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as 'legacy_dim_products.csv'\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Retrieve product data from S3\n",
    "products_df = data_extractor.extract_from_s3(s3_uri)\n",
    "\n",
    "# Check if the DataFrame was retrieved successfully\n",
    "if products_df is not None:\n",
    "    print(\"Data before cleaning:\")\n",
    "    display(products_df.head())  # Use display to render the DataFrame in Jupyter\n",
    "    # Save the DataFrame as 'legend_dim_products'\n",
    "    products_df.to_csv('legacy_dim_products.csv', index=False)\n",
    "    print(\"DataFrame saved as 'legacy_dim_products.csv'\")\n",
    "else:\n",
    "    print(\"Failed to retrieve product data from S3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Product Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after cleaning:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price_gbp</th>\n",
       "      <th>category</th>\n",
       "      <th>EAN</th>\n",
       "      <th>date_added</th>\n",
       "      <th>uuid</th>\n",
       "      <th>removed</th>\n",
       "      <th>product_code</th>\n",
       "      <th>weight_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FurReal Dazzlin' Dimples My Playful Dolphin</td>\n",
       "      <td>39.99</td>\n",
       "      <td>toys-and-games</td>\n",
       "      <td>7425710935115</td>\n",
       "      <td>2005-12-02</td>\n",
       "      <td>83dc0a69-f96f-4c34-bcb7-928acae19a94</td>\n",
       "      <td>Still_avaliable</td>\n",
       "      <td>R7-3126933h</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Tiffany's World Day Out At The Park</td>\n",
       "      <td>12.99</td>\n",
       "      <td>toys-and-games</td>\n",
       "      <td>487128731892</td>\n",
       "      <td>2006-01-09</td>\n",
       "      <td>712254d7-aea7-4310-aff8-8bcdd0aec7ff</td>\n",
       "      <td>Still_avaliable</td>\n",
       "      <td>C2-7287916l</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Tiffany's World Pups Picnic Playset</td>\n",
       "      <td>7.00</td>\n",
       "      <td>toys-and-games</td>\n",
       "      <td>1945816904649</td>\n",
       "      <td>1997-03-29</td>\n",
       "      <td>b089ef6f-b628-4e37-811d-fffe0102ba64</td>\n",
       "      <td>Still_avaliable</td>\n",
       "      <td>S7-1175877v</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Tiffany's World Wildlife Park Adventures</td>\n",
       "      <td>12.99</td>\n",
       "      <td>toys-and-games</td>\n",
       "      <td>1569790890899</td>\n",
       "      <td>2013-03-20</td>\n",
       "      <td>d55de422-8b98-47d6-9991-e4bc4c5c0cb0</td>\n",
       "      <td>Removed</td>\n",
       "      <td>D8-8421505n</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Cosatto Cosy Dolls Pram</td>\n",
       "      <td>30.00</td>\n",
       "      <td>toys-and-games</td>\n",
       "      <td>7142740213920</td>\n",
       "      <td>2007-12-23</td>\n",
       "      <td>7945b657-cb02-4cc5-96cf-f65ed0a8f235</td>\n",
       "      <td>Still_avaliable</td>\n",
       "      <td>B6-2596063a</td>\n",
       "      <td>1.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                 product_name  product_price_gbp  \\\n",
       "0           0  FurReal Dazzlin' Dimples My Playful Dolphin              39.99   \n",
       "1           1          Tiffany's World Day Out At The Park              12.99   \n",
       "2           2          Tiffany's World Pups Picnic Playset               7.00   \n",
       "3           3     Tiffany's World Wildlife Park Adventures              12.99   \n",
       "4           4                      Cosatto Cosy Dolls Pram              30.00   \n",
       "\n",
       "         category            EAN date_added  \\\n",
       "0  toys-and-games  7425710935115 2005-12-02   \n",
       "1  toys-and-games   487128731892 2006-01-09   \n",
       "2  toys-and-games  1945816904649 1997-03-29   \n",
       "3  toys-and-games  1569790890899 2013-03-20   \n",
       "4  toys-and-games  7142740213920 2007-12-23   \n",
       "\n",
       "                                   uuid          removed product_code  \\\n",
       "0  83dc0a69-f96f-4c34-bcb7-928acae19a94  Still_avaliable  R7-3126933h   \n",
       "1  712254d7-aea7-4310-aff8-8bcdd0aec7ff  Still_avaliable  C2-7287916l   \n",
       "2  b089ef6f-b628-4e37-811d-fffe0102ba64  Still_avaliable  S7-1175877v   \n",
       "3  d55de422-8b98-47d6-9991-e4bc4c5c0cb0          Removed  D8-8421505n   \n",
       "4  7945b657-cb02-4cc5-96cf-f65ed0a8f235  Still_avaliable  B6-2596063a   \n",
       "\n",
       "   weight_kg  \n",
       "0       1.60  \n",
       "1       0.48  \n",
       "2       0.59  \n",
       "3       0.54  \n",
       "4       1.91  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 4: Clean the Data\n",
    "if 'products_df' in locals():\n",
    "    data_cleaner = DataCleaning()\n",
    "    cleaned_df = data_cleaner.clean_product_data(products_df)\n",
    "\n",
    "    # Step 5: Display the cleaned data\n",
    "    print(\"Data after cleaning:\")\n",
    "    display(cleaned_df.head())\n",
    "else:\n",
    "    print(\"Product data not available, cannot proceed with cleaning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Local Database and Upload Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database engine initialized successfully.\n",
      "Data uploaded to table dim_products successfully.\n",
      "Cleaned data uploaded to the local database as 'dim_products'\n",
      "Data uploaded to table legacy_dim_products successfully.\n",
      "Legend data uploaded to the local database as 'legacy_dim_products'\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Connect to the Local Database\n",
    "if 'cleaned_df' in locals():\n",
    "    local_db_connector = DatabaseConnector(config_path='local_db_creds.yaml')\n",
    "\n",
    "    # Step 7: Upload the cleaned data to the local database\n",
    "    local_db_connector.upload_to_db(cleaned_df, \"dim_products\")\n",
    "    print(\"Cleaned data uploaded to the local database as 'dim_products'\")\n",
    "\n",
    "    # Upload the legacy_dim_products dataframe\n",
    "    legend_dim_products = pd.read_csv('legacy_dim_products.csv')\n",
    "    local_db_connector.upload_to_db(legend_dim_products, \"legacy_dim_products\")\n",
    "    print(\"Legend data uploaded to the local database as 'legacy_dim_products'\")\n",
    "else:\n",
    "    print(\"Cleaned data not available, cannot upload.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to AWS RDS Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database engine initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Connect to the AWS RDS Database\n",
    "rds_db_connector = DatabaseConnector(config_path='aws_db_creds.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Data from RDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data before cleaning:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>date_uuid</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>user_uuid</th>\n",
       "      <th>card_number</th>\n",
       "      <th>store_code</th>\n",
       "      <th>product_code</th>\n",
       "      <th>1</th>\n",
       "      <th>product_quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9476f17e-5d6a-4117-874d-9cdb38ca1fa6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>93caf182-e4e9-4c6e-bebb-60a1a9dcf9b8</td>\n",
       "      <td>30060773296197</td>\n",
       "      <td>BL-8387506C</td>\n",
       "      <td>R7-3126933h</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0423a395-a04d-4e4a-bd0f-d237cbd5a295</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8fe96c3a-d62d-4eb5-b313-cf12d9126a49</td>\n",
       "      <td>349624180933183</td>\n",
       "      <td>WEB-1388012W</td>\n",
       "      <td>C2-7287916l</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>65187294-bb16-4519-adc0-787bbe423970</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>fc461df4-b919-48b2-909e-55c95a03fe6b</td>\n",
       "      <td>3529023891650490</td>\n",
       "      <td>CH-01D85C8D</td>\n",
       "      <td>S7-1175877v</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>579e21f7-13cb-436b-83ad-33687a4eb337</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>6104719f-ef14-4b09-bf04-fb0c4620acb0</td>\n",
       "      <td>213142929492281</td>\n",
       "      <td>CL-C183BE4B</td>\n",
       "      <td>D8-8421505n</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>00ab86c3-2039-4674-b9c1-adbcbbf525bd</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>9523a6d3-b2dd-4670-a51a-36aebc89f579</td>\n",
       "      <td>502067329974</td>\n",
       "      <td>SO-B5B9CB3B</td>\n",
       "      <td>B6-2596063a</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index                             date_uuid first_name last_name  \\\n",
       "0        0      0  9476f17e-5d6a-4117-874d-9cdb38ca1fa6       None      None   \n",
       "1        1      1  0423a395-a04d-4e4a-bd0f-d237cbd5a295       None      None   \n",
       "2        2      2  65187294-bb16-4519-adc0-787bbe423970       None      None   \n",
       "3        3      3  579e21f7-13cb-436b-83ad-33687a4eb337       None      None   \n",
       "4        4      4  00ab86c3-2039-4674-b9c1-adbcbbf525bd       None      None   \n",
       "\n",
       "                              user_uuid       card_number    store_code  \\\n",
       "0  93caf182-e4e9-4c6e-bebb-60a1a9dcf9b8    30060773296197   BL-8387506C   \n",
       "1  8fe96c3a-d62d-4eb5-b313-cf12d9126a49   349624180933183  WEB-1388012W   \n",
       "2  fc461df4-b919-48b2-909e-55c95a03fe6b  3529023891650490   CH-01D85C8D   \n",
       "3  6104719f-ef14-4b09-bf04-fb0c4620acb0   213142929492281   CL-C183BE4B   \n",
       "4  9523a6d3-b2dd-4670-a51a-36aebc89f579      502067329974   SO-B5B9CB3B   \n",
       "\n",
       "  product_code     1  product_quantity  \n",
       "0  R7-3126933h  None                 3  \n",
       "1  C2-7287916l  None                 2  \n",
       "2  S7-1175877v  None                 2  \n",
       "3  D8-8421505n  None                 2  \n",
       "4  B6-2596063a  None                 2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as 'legacy_fact_orders.csv'\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Extract Data from RDS\n",
    "data_extractor = DataExtractor(rds_db_connector)\n",
    "orders_df = data_extractor.read_rds_table('orders_table')\n",
    "\n",
    "# Check if the DataFrame was retrieved successfully\n",
    "if orders_df is not None:\n",
    "    print(\"Data before cleaning:\")\n",
    "    display(orders_df.head())  # Use display to render the DataFrame in Jupyter\n",
    "    # Save the DataFrame as 'legacy_fact_orders'\n",
    "    orders_df.to_csv('legacy_fact_orders.csv', index=False)\n",
    "    print(\"DataFrame saved as 'legacy_fact_orders.csv'\")\n",
    "else:\n",
    "    print(\"Failed to retrieve data from RDS.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Orders Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after cleaning:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>date_uuid</th>\n",
       "      <th>user_uuid</th>\n",
       "      <th>card_number</th>\n",
       "      <th>store_code</th>\n",
       "      <th>product_code</th>\n",
       "      <th>product_quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9476f17e-5d6a-4117-874d-9cdb38ca1fa6</td>\n",
       "      <td>93caf182-e4e9-4c6e-bebb-60a1a9dcf9b8</td>\n",
       "      <td>30060773296197</td>\n",
       "      <td>BL-8387506C</td>\n",
       "      <td>R7-3126933h</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0423a395-a04d-4e4a-bd0f-d237cbd5a295</td>\n",
       "      <td>8fe96c3a-d62d-4eb5-b313-cf12d9126a49</td>\n",
       "      <td>349624180933183</td>\n",
       "      <td>WEB-1388012W</td>\n",
       "      <td>C2-7287916l</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>65187294-bb16-4519-adc0-787bbe423970</td>\n",
       "      <td>fc461df4-b919-48b2-909e-55c95a03fe6b</td>\n",
       "      <td>3529023891650490</td>\n",
       "      <td>CH-01D85C8D</td>\n",
       "      <td>S7-1175877v</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>579e21f7-13cb-436b-83ad-33687a4eb337</td>\n",
       "      <td>6104719f-ef14-4b09-bf04-fb0c4620acb0</td>\n",
       "      <td>213142929492281</td>\n",
       "      <td>CL-C183BE4B</td>\n",
       "      <td>D8-8421505n</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>00ab86c3-2039-4674-b9c1-adbcbbf525bd</td>\n",
       "      <td>9523a6d3-b2dd-4670-a51a-36aebc89f579</td>\n",
       "      <td>502067329974</td>\n",
       "      <td>SO-B5B9CB3B</td>\n",
       "      <td>B6-2596063a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index                             date_uuid  \\\n",
       "0        0      0  9476f17e-5d6a-4117-874d-9cdb38ca1fa6   \n",
       "1        1      1  0423a395-a04d-4e4a-bd0f-d237cbd5a295   \n",
       "2        2      2  65187294-bb16-4519-adc0-787bbe423970   \n",
       "3        3      3  579e21f7-13cb-436b-83ad-33687a4eb337   \n",
       "4        4      4  00ab86c3-2039-4674-b9c1-adbcbbf525bd   \n",
       "\n",
       "                              user_uuid       card_number    store_code  \\\n",
       "0  93caf182-e4e9-4c6e-bebb-60a1a9dcf9b8    30060773296197   BL-8387506C   \n",
       "1  8fe96c3a-d62d-4eb5-b313-cf12d9126a49   349624180933183  WEB-1388012W   \n",
       "2  fc461df4-b919-48b2-909e-55c95a03fe6b  3529023891650490   CH-01D85C8D   \n",
       "3  6104719f-ef14-4b09-bf04-fb0c4620acb0   213142929492281   CL-C183BE4B   \n",
       "4  9523a6d3-b2dd-4670-a51a-36aebc89f579      502067329974   SO-B5B9CB3B   \n",
       "\n",
       "  product_code  product_quantity  \n",
       "0  R7-3126933h                 3  \n",
       "1  C2-7287916l                 2  \n",
       "2  S7-1175877v                 2  \n",
       "3  D8-8421505n                 2  \n",
       "4  B6-2596063a                 2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 3: Clean the Data\n",
    "if 'orders_df' in locals():\n",
    "    data_cleaner = DataCleaning()\n",
    "    cleaned_df = data_cleaner.clean_orders_data(orders_df)\n",
    "\n",
    "    # Step 4: Display the cleaned data\n",
    "    print(\"Data after cleaning:\")\n",
    "    display(cleaned_df.head())\n",
    "else:\n",
    "    print(\"Orders data not available, cannot proceed with cleaning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Local Database and Upload Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database engine initialized successfully.\n",
      "Data uploaded to table orders_table successfully.\n",
      "Cleaned data uploaded to the local database as 'orders_table'\n",
      "Data uploaded to table legacy_orders_table successfully.\n",
      "Legend data uploaded to the local database as 'legacy_orders_table'\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Connect to the Local Database\n",
    "if 'cleaned_df' in locals():\n",
    "    local_db_connector = DatabaseConnector(config_path='local_db_creds.yaml')\n",
    "\n",
    "    # Step 6: Upload the cleaned data to the local database\n",
    "    local_db_connector.upload_to_db(cleaned_df, \"orders_table\")\n",
    "    print(\"Cleaned data uploaded to the local database as 'orders_table'\")\n",
    "\n",
    "    # Upload the legacy_orders_table dataframe\n",
    "    legend_orders_table = pd.read_csv('legacy_fact_orders.csv')\n",
    "    local_db_connector.upload_to_db(legend_orders_table, \"legacy_orders_table\")\n",
    "    print(\"Legend data uploaded to the local database as 'legacy_orders_table'\")\n",
    "else:\n",
    "    print(\"Cleaned data not available, cannot upload.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define JSON URL and Filename, Fetch and Save JSON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw JSON data fetched and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Fetch the JSON data from the S3 URL and save it to a file\n",
    "json_url = \"https://data-handling-public.s3.eu-west-1.amazonaws.com/date_details.json\"\n",
    "filename = \"date_details.json\"\n",
    "\n",
    "# Create an instance of DataCleaning to handle JSON operations\n",
    "data_cleaner = DataCleaning()\n",
    "\n",
    "# Fetch and save the JSON data\n",
    "raw_json_data = data_cleaner.fetch_and_save_json(json_url, filename)\n",
    "\n",
    "# Check if the JSON data was successfully retrieved\n",
    "if raw_json_data:\n",
    "    print(\"Raw JSON data fetched and saved successfully.\")\n",
    "else:\n",
    "    print(\"Failed to fetch JSON data from the given URL.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the JSON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after reformatting to DataFrame:\n",
      "  timestamp month  year day time_period                             date_uuid\n",
      "0  22:00:06     9  2012  19     Evening  3b7ca996-37f9-433f-b6d0-ce8391b615ad\n",
      "1  22:44:06     2  1997  10     Evening  adc86836-6c35-49ca-bb0d-65b6507a00fa\n",
      "2  10:05:37     4  1994  15     Morning  5ff791bf-d8e0-4f86-8ceb-c7b60bef9b31\n",
      "3  17:29:27    11  2001   6      Midday  1b01fcef-5ab9-404c-b0d4-1e75a0bd19d8\n",
      "4  22:40:33    12  2015  31     Evening  dfa907c1-f6c5-40f0-aa0d-40ed77ac5a44\n",
      "Data after removing null rows:\n",
      "  timestamp month  year day time_period                             date_uuid\n",
      "0  22:00:06     9  2012  19     Evening  3b7ca996-37f9-433f-b6d0-ce8391b615ad\n",
      "1  22:44:06     2  1997  10     Evening  adc86836-6c35-49ca-bb0d-65b6507a00fa\n",
      "2  10:05:37     4  1994  15     Morning  5ff791bf-d8e0-4f86-8ceb-c7b60bef9b31\n",
      "3  17:29:27    11  2001   6      Midday  1b01fcef-5ab9-404c-b0d4-1e75a0bd19d8\n",
      "4  22:40:33    12  2015  31     Evening  dfa907c1-f6c5-40f0-aa0d-40ed77ac5a44\n",
      "Data after removing invalid rows:\n",
      "  timestamp month  year day time_period                             date_uuid\n",
      "0  22:00:06     9  2012  19     Evening  3b7ca996-37f9-433f-b6d0-ce8391b615ad\n",
      "1  22:44:06     2  1997  10     Evening  adc86836-6c35-49ca-bb0d-65b6507a00fa\n",
      "2  10:05:37     4  1994  15     Morning  5ff791bf-d8e0-4f86-8ceb-c7b60bef9b31\n",
      "3  17:29:27    11  2001   6      Midday  1b01fcef-5ab9-404c-b0d4-1e75a0bd19d8\n",
      "4  22:40:33    12  2015  31     Evening  dfa907c1-f6c5-40f0-aa0d-40ed77ac5a44\n",
      "Data after combining datetime columns:\n",
      "  time_period                             date_uuid            datetime\n",
      "0     Evening  3b7ca996-37f9-433f-b6d0-ce8391b615ad 2012-09-19 22:00:06\n",
      "1     Evening  adc86836-6c35-49ca-bb0d-65b6507a00fa 1997-02-10 22:44:06\n",
      "2     Morning  5ff791bf-d8e0-4f86-8ceb-c7b60bef9b31 1994-04-15 10:05:37\n",
      "3      Midday  1b01fcef-5ab9-404c-b0d4-1e75a0bd19d8 2001-11-06 17:29:27\n",
      "4     Evening  dfa907c1-f6c5-40f0-aa0d-40ed77ac5a44 2015-12-31 22:40:33\n",
      "Final cleaned data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_period</th>\n",
       "      <th>date_uuid</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Evening</td>\n",
       "      <td>3b7ca996-37f9-433f-b6d0-ce8391b615ad</td>\n",
       "      <td>2012-09-19 22:00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Evening</td>\n",
       "      <td>adc86836-6c35-49ca-bb0d-65b6507a00fa</td>\n",
       "      <td>1997-02-10 22:44:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Morning</td>\n",
       "      <td>5ff791bf-d8e0-4f86-8ceb-c7b60bef9b31</td>\n",
       "      <td>1994-04-15 10:05:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Midday</td>\n",
       "      <td>1b01fcef-5ab9-404c-b0d4-1e75a0bd19d8</td>\n",
       "      <td>2001-11-06 17:29:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Evening</td>\n",
       "      <td>dfa907c1-f6c5-40f0-aa0d-40ed77ac5a44</td>\n",
       "      <td>2015-12-31 22:40:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  time_period                             date_uuid            datetime\n",
       "0     Evening  3b7ca996-37f9-433f-b6d0-ce8391b615ad 2012-09-19 22:00:06\n",
       "1     Evening  adc86836-6c35-49ca-bb0d-65b6507a00fa 1997-02-10 22:44:06\n",
       "2     Morning  5ff791bf-d8e0-4f86-8ceb-c7b60bef9b31 1994-04-15 10:05:37\n",
       "3      Midday  1b01fcef-5ab9-404c-b0d4-1e75a0bd19d8 2001-11-06 17:29:27\n",
       "4     Evening  dfa907c1-f6c5-40f0-aa0d-40ed77ac5a44 2015-12-31 22:40:33"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 2: Clean the saved JSON data\n",
    "if raw_json_data:\n",
    "    cleaned_df = data_cleaner.clean_date_events_data(raw_json_data)\n",
    "\n",
    "    # Display the cleaned data if available\n",
    "    if cleaned_df is not None:\n",
    "        print(\"Final cleaned data:\")\n",
    "        display(cleaned_df.head())  # Use display() for better visualization in Jupyter\n",
    "    else:\n",
    "        print(\"Failed to clean the JSON data.\")\n",
    "else:\n",
    "    print(\"JSON data not available, cannot proceed with cleaning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Local Database and Upload Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database engine initialized successfully.\n",
      "Data uploaded to table dim_date_times successfully.\n",
      "Cleaned data uploaded to the local database as 'dim_date_times'\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Connect to the Local Database and Upload the Cleaned Data\n",
    "if 'cleaned_df' in locals():\n",
    "    # Create an instance of DatabaseConnector\n",
    "    local_db_connector = DatabaseConnector(config_path='local_db_creds.yaml')\n",
    "\n",
    "    # Step 4: Upload the cleaned data to the local database as 'dim_date_times'\n",
    "    local_db_connector.upload_to_db(cleaned_df, \"dim_date_times\")\n",
    "    print(\"Cleaned data uploaded to the local database as 'dim_date_times'\")\n",
    "else:\n",
    "    print(\"Cleaned data not available, cannot upload.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_centre",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
